Generative AI: How unfair training permeate stereotypes?
It goes without saying that platforms like ChatGPT and DALL-E have not only become household names but have also reshaped the very fabric of our interactions with technology. However, as the surge in user numbers and corporate adoption captures headlines, a critical undercurrent flows beneath the surface—the undeniable impact of biased training data on these AI marvels.
Generative artificial intelligence (AI) has taken center stage in 2023, exemplified by the widespread adoption of platforms like ChatGPT and DALL-E. During OpenAI's inaugural developer conference, CEO Sam Altman proudly announced the milestone of ChatGPT reaching 100 million weekly users. This widespread popularity extends to corporate circles, with a staggering 92% of Fortune 500 companies integrating OpenAI APIs into their systems (OpenAI, 2023).For context, generative AI models use neural networks dubbed the transformer model to identify patterns and structures within existing data to generate new and original content (NVIDIA, 2022). The transformer model is a type of neural network that gains an understanding of context and meaning by examining relationships within sequential data, such as the words in a sentence. This is achieved through the application of attention or self-attention mechanisms, employing mathematical techniques to discern connections among elements in a series (Merritt, 2022).
Generative AI systems rely on expansive data models, serving as their "vocabulary," which undergo extensive training on a substantial dataset of images, text, and their interconnected relationships through numerous iterative processes (Cheong, et al., 2023). The technology thus allows users to swiftly create new content from diverse inputs or prompts, including text and images. However, because they are trained using large datasets, generative AI models also unintentionally produce content that mirrors prevailing stereotypes and biases within society.
In their research, Cheong, et al. (2023) explained that AI models rely on a substantial amount of human input. For example, an image generation system learns from a vast collection of input images to identify visual characteristics associated with specific concepts, such as distinguishing a doctor from a chef. The authors emphasize that, in essence, these concepts involve correlations between different tokens. For instance, 'doctor' correlates with 'syringe,' and 'chef' correlates with 'spatula.' Each token also carries an encoded list indicating its likelihood of co-occurring with other tokens. Therefore, when the system encounters a 'doctor,' it makes a 'syringe' much more likely to appear than a 'spatula.’
However, the authors stressed that the data used to train such systems is not immune to, and indeed, dependent on human bias. For instance, if most images used for training primarily feature white men in the medical profession, these systems may establish a correlation between specific features like 'white' and 'male' with the token 'doctor.'
Indeed, Cheong, et al. (2023) concluded in their research that DALL-E Mini, an open source derivative of DALL-E, implicates gendered work—as well as racial—stereotypes. It misrepresented occupations as dominated or not dominated by women when real life statistics (such as from the US Labor Department) indicates otherwise. The research suggests that generative AI models inherit and perpetuate biases present in the training data. In this case, the bias could stem from a limited representation of diverse images, potentially leading to an association between certain features and professional roles in the model that may not accurately reflect real-world diversity.
With that being said, we could only discern that AI is only as fair as its training data. Since the biases from the training data reflect the biases present in society, AI, in essence, thus ultimately acts as a mirror of our society.  As we marvel at the prowess of these systems, it is incumbent upon us to confront the sobering reality that they may inadvertently perpetuate and amplify societal prejudices. The call to action is clear — a conscientious approach to the development and deployment of generative AI is imperative to ensure that these technological marvels contribute to a future where innovation is a force for positive change, unshackled from the chains of ingrained biases that have plagued human history. The promise of a truly equitable and unbiased AI future beckons, and our choices today will shape the contours of that tomorrow.


Bibliography
Cheong, M., Abedina, E., Ferreira, M., Reimann, R., Chalson, S., Robinson, P., . . . Klein, C. (2023, April). Investigating gender and racial biases in DALL-E Mini Images. Retrieved from PhilArchive: https://philarchive.org/archive/CHEIGA-2
Merritt, R. (2022). What Is a Transformer Model? Retrieved from NVIDIA Blog Site: https://blogs.nvidia.com/blog/what-is-a-transformer-model/#:~:text=A%20transformer%20model%20is%20a,the%20words%20in%20this%20sentence.
NVIDIA. (2022). What is Generative AI? Retrieved from https://www.nvidia.com/en-us/glossary/data-science/generative-ai/
OpenAI. (2023, November). OpenAI DevDay: Opening Keynote [Video]. Retrieved from YouTube: https://www.youtube.com/watch?v=U9mJuUkhUzk

